llama-index
llama-index-core==0.10.20.post1
torch==2.0.1
attention_sinks
transformers